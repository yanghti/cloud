<!DOCTYPE html>
<html>
  <head>
    <title>Cloud-Notes</title>
    
      <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="generator" content="Hugo 0.48" />
<title>ceph-deploy :: Cloud-Notes</title>
<link rel="shortcut icon" href="/cloud/images/favicon.png" type="image/x-icon" />
<link href="/cloud/css/font-awesome.min.css" rel="stylesheet">
<link href="/cloud/css/nucleus.css" rel="stylesheet">
<link href="/cloud/theme-flex/style.css" rel="stylesheet">

<link rel="stylesheet" href="/cloud/css/bootstrap.min.css">
<script src="/cloud/js/jquery-2.x.min.js"></script>
<script type="text/javascript">
      var baseurl = "https:\/\/yanghti.github.io\/cloud";
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79101-13', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>
  <body data-url="/cloud/cloud-storage/ceph/operations/ceph-deploy/">
    
      <header>
  <div class="logo">
    
	
  
    <a class="baselink" href="https://yanghti.github.io/cloud">Cloud-Notes</a>
  

  </div>
  <div class="burger"><a href="javascript:void(0);" style="font-size:15px;">&#9776;</a></div>
    <nav class="shortcuts">
            <li class="" role="">
                <a href="https://github.com/vjeantet/hugo-theme-docdock"  rel="noopener">
                  <i class='fa fa-github'></i> <label>Github repo</label>
                </a>
            </li>
            <li class="" role="">
                <a href="https://github.com/vjeantet/hugo-theme-docdock/archive/master.zip"  rel="noopener">
                  <i class='fa fa-cloud-download'></i> <label>Download</label>
                </a>
            </li>
            <li class="" role="">
                <a href="https://gohugo.io/"  rel="noopener">
                  <i class='fa fa-bookmark'></i> <label>Hugo Documentation</label>
                </a>
            </li>
            <li class="" role="">
                <a href="/cloud/credits"  rel="noopener">
                  <i class='fa fa-bullhorn'></i> <label>Credits</label>
                </a>
            </li>
    </nav>
</header>
<article>
  <aside>
    <ul class="menu">
          <li data-nav-id="/cloud/" class="dd-item">
          <a href="/cloud/">
            <i class="fa fa-fw fa-home"></i>
          </a>
          </li>
    <li data-nav-id="/cloud/getting-start/" class="dd-item haschildren
        ">
      <div>
      <a href="/cloud/getting-start/">Getting started</a><i class="fa fa-angle-right fa-lg category-icon"></i><i class="fa fa-circle-thin read-icon"></i>
      </div>
        <ul>
      <li data-nav-id="/cloud/getting-start/installation/" class="dd-item">
        <div>
          <a href="/cloud/getting-start/installation/">
            Installation
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/cloud/getting-start/configuration/" class="dd-item">
        <div>
          <a href="/cloud/getting-start/configuration/">
            Configuration
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
        </ul>
    </li>
    <li data-nav-id="/cloud/cloud-computing/" class="dd-item
        ">
      <div>
      <a href="/cloud/cloud-computing/">cloud computing</a><i class="fa fa-circle-thin read-icon"></i>
      </div>
    </li>
    <li data-nav-id="/cloud/cloud-storage/" class="dd-item parent haschildren
        ">
      <div>
      <a href="/cloud/cloud-storage/">cloud storage</a>
            <i class="fa fa-angle-down fa-lg category-icon"></i><i class="fa fa-circle-thin read-icon"></i>
      </div>
        <ul>
    <li data-nav-id="/cloud/cloud-storage/ceph/" class="dd-item parent haschildren
        ">
      <div>
      <a href="/cloud/cloud-storage/ceph/">ceph</a>
            <i class="fa fa-angle-down fa-lg category-icon"></i><i class="fa fa-circle-thin read-icon"></i>
      </div>
        <ul>
    <li data-nav-id="/cloud/cloud-storage/ceph/operations/" class="dd-item parent haschildren
        ">
      <div>
      <a href="/cloud/cloud-storage/ceph/operations/">operations</a>
            <i class="fa fa-angle-down fa-lg category-icon"></i><i class="fa fa-circle-thin read-icon"></i>
      </div>
        <ul>
      <li data-nav-id="/cloud/cloud-storage/ceph/operations/ceph-build/" class="dd-item">
        <div>
          <a href="/cloud/cloud-storage/ceph/operations/ceph-build/">
            ceph-build
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/cloud/cloud-storage/ceph/operations/ceph-osd/" class="dd-item">
        <div>
          <a href="/cloud/cloud-storage/ceph/operations/ceph-osd/">
            ceph-osd
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/cloud/cloud-storage/ceph/operations/ceph-deploy/" class="dd-item active">
        <div>
          <a href="/cloud/cloud-storage/ceph/operations/ceph-deploy/">
            ceph-deploy
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/cloud/cloud-storage/ceph/operations/ceph-mgr-dashboard/" class="dd-item">
        <div>
          <a href="/cloud/cloud-storage/ceph/operations/ceph-mgr-dashboard/">
            ceph-mgr-dashboard
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/cloud/cloud-storage/ceph/operations/ceph-bench/" class="dd-item">
        <div>
          <a href="/cloud/cloud-storage/ceph/operations/ceph-bench/">
            ceph-bench
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/cloud/cloud-storage/ceph/operations/disk-scale/" class="dd-item">
        <div>
          <a href="/cloud/cloud-storage/ceph/operations/disk-scale/">
            disk-scale
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
        </ul>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li data-nav-id="/cloud/cloud-scheduling/" class="dd-item
        ">
      <div>
      <a href="/cloud/cloud-scheduling/">cloud scheduling</a><i class="fa fa-circle-thin read-icon"></i>
      </div>
    </li>
    <li data-nav-id="/cloud/search/" class="dd-item
        ">
      <div>
      <a href="/cloud/search/">About the Search Engine</a><i class="fa fa-circle-thin read-icon"></i>
      </div>
    </li>




    </ul>
    <section><center>

<a class="github-button" href="https://github.com/vjeantet/hugo-theme-docdock/archive/master.zip" data-icon="octicon-cloud-download" aria-label="Download vjeantet/hugo-theme-docdock on GitHub">Download</a>


<a class="github-button" href="https://github.com/vjeantet/hugo-theme-docdock" data-icon="octicon-star" data-show-count="false" aria-label="Star vjeantet/hugo-theme-docdock on GitHub">Star</a>


<a class="github-button" href="https://github.com/vjeantet/hugo-theme-docdock/fork" data-icon="octicon-repo-forked" data-show-count="true" aria-label="Fork vjeantet/hugo-theme-docdock on GitHub">Fork</a>

</center>

<script async defer src="https://buttons.github.io/buttons.js"></script>
    </section>
  </aside>
  <section class="page">
    
    <div class="nav-select">
      <center>Navigation : 
        <select onchange="javascript:location.href = this.value;">
          
    <option value="/cloud/getting-start/" >
   Getting started</option>
    <option value="/cloud/cloud-computing/" >
   cloud computing</option>
    <option value="/cloud/cloud-storage/" >
   cloud storage</option> 
    <option value="/cloud/cloud-storage/ceph/" >
  - 
   ceph</option> 
    <option value="/cloud/cloud-storage/ceph/operations/" >
  -- 
   operations</option> 
      <option value="/cloud/cloud-storage/ceph/operations/ceph-build/" >--- ceph-build</option>
      <option value="/cloud/cloud-storage/ceph/operations/ceph-osd/" >--- ceph-osd</option>
      <option value="/cloud/cloud-storage/ceph/operations/ceph-deploy/"  selected>--- ceph-deploy</option>
      <option value="/cloud/cloud-storage/ceph/operations/ceph-mgr-dashboard/" >--- ceph-mgr-dashboard</option>
      <option value="/cloud/cloud-storage/ceph/operations/ceph-bench/" >--- ceph-bench</option>
      <option value="/cloud/cloud-storage/ceph/operations/disk-scale/" >--- disk-scale</option>
  
  
  
    <option value="/cloud/cloud-scheduling/" >
   cloud scheduling</option>
    <option value="/cloud/create-page/" >
   Create Page</option>
    <option value="/cloud/content-organisation/" >
   Content Organisation</option>
    <option value="/cloud/shortcodes/" >
   Shortcodes</option>
    <option value="/cloud/search/" >
   About the Search Engine</option>



        </select>
      </center>
    </div>
      <div>
        <div class="searchbox">
          <input data-search-input id="search-by" type="text" placeholder="Search...">
        </div>
        <script type="text/javascript" src="/cloud/js/lunr.min.js"></script>
        <script type="text/javascript" src="/cloud/js/auto-complete.js"></script>
        <link href="/cloud/css/auto-complete.css" rel="stylesheet">
        <script type="text/javascript">
          
              var baseurl = "https:\/\/yanghti.github.io\/cloud";
          
        </script>
        <script type="text/javascript" src="/cloud/js/search.js"></script>
      </div>
    

    <h1>ceph-deploy</h1>
    
    
    
    

<h1 id="ceph-deploy">ceph deploy</h1>

<hr />

<h2 id="资源">资源</h2>

<hr />

<ol>
<li>ceph deploy</li>
</ol>

<h2 id="步骤">步骤</h2>

<hr />

<ol>
<li><p>overview</p>

<p>```</p>

<ol>
<li>mon</li>
<li>mgr</li>
<li>osd
```</li>
</ol></li>

<li><p>mon</p>

<pre><code>[ceph-sh-admin@ceph-sh-admin ceph-deploy]$ ceph-deploy mon create-initial
[ceph_deploy.conf][DEBUG ] found configuration file at: /home/ceph-sh-admin/.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy mon create-initial
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f203c9bacb0&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x7f203ce33398&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  keyrings                      : None
[ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph-sh-node1 ceph-sh-node2 ceph-sh-node3
[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-sh-node1 ...
[ceph-sh-node1][DEBUG ] connection detected need for sudo
[ceph-sh-node1][DEBUG ] connected to host: ceph-sh-node1 
[ceph-sh-node1][DEBUG ] detect platform information from remote host
[ceph-sh-node1][DEBUG ] detect machine type
[ceph-sh-node1][DEBUG ] find the location of an executable
[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.5.1804 Core
[ceph-sh-node1][DEBUG ] determining if provided host has same hostname in remote
[ceph-sh-node1][DEBUG ] get remote short hostname
[ceph-sh-node1][DEBUG ] deploying mon to ceph-sh-node1
[ceph-sh-node1][DEBUG ] get remote short hostname
[ceph-sh-node1][DEBUG ] remote hostname: ceph-sh-node1
[ceph-sh-node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[ceph-sh-node1][DEBUG ] create the mon path if it does not exist
[ceph-sh-node1][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-sh-node1/done
[ceph-sh-node1][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph-sh-node1/done
[ceph-sh-node1][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph-sh-node1.mon.keyring
[ceph-sh-node1][DEBUG ] create the monitor keyring file
[ceph-sh-node1][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i ceph-sh-node1 --keyring /var/lib/ceph/tmp/ceph-ceph-sh-node1.mon.keyring --setuser 167 --setgroup 167
[ceph-sh-node1][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph-sh-node1.mon.keyring
[ceph-sh-node1][DEBUG ] create a done file to avoid re-doing the mon deployment
[ceph-sh-node1][DEBUG ] create the init path if it does not exist
[ceph-sh-node1][INFO  ] Running command: sudo systemctl enable ceph.target
[ceph-sh-node1][INFO  ] Running command: sudo systemctl enable ceph-mon@ceph-sh-node1
[ceph-sh-node1][WARNIN] Created symlink from /etc/systemd/system/ceph-mon.target.wants/ceph-mon@ceph-sh-node1.service to /usr/lib/systemd/system/ceph-mon@.service.
[ceph-sh-node1][INFO  ] Running command: sudo systemctl start ceph-mon@ceph-sh-node1
[ceph-sh-node1][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node1.asok mon_status
[ceph-sh-node1][DEBUG ] ********************************************************************************
[ceph-sh-node1][DEBUG ] status for monitor: mon.ceph-sh-node1
[ceph-sh-node1][DEBUG ] {
[ceph-sh-node1][DEBUG ]   &quot;election_epoch&quot;: 0, 
[ceph-sh-node1][DEBUG ]   &quot;extra_probe_peers&quot;: [
[ceph-sh-node1][DEBUG ]     &quot;192.168.59.202:6789/0&quot;, 
[ceph-sh-node1][DEBUG ]     &quot;192.168.59.203:6789/0&quot;
[ceph-sh-node1][DEBUG ]   ], 
[ceph-sh-node1][DEBUG ]   &quot;feature_map&quot;: {
[ceph-sh-node1][DEBUG ]     &quot;mon&quot;: [
[ceph-sh-node1][DEBUG ]       {
[ceph-sh-node1][DEBUG ]         &quot;features&quot;: &quot;0x3ffddff8ffa4fffb&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;num&quot;: 1, 
[ceph-sh-node1][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;
[ceph-sh-node1][DEBUG ]       }
[ceph-sh-node1][DEBUG ]     ]
[ceph-sh-node1][DEBUG ]   }, 
[ceph-sh-node1][DEBUG ]   &quot;features&quot;: {
[ceph-sh-node1][DEBUG ]     &quot;quorum_con&quot;: &quot;0&quot;, 
[ceph-sh-node1][DEBUG ]     &quot;quorum_mon&quot;: [], 
[ceph-sh-node1][DEBUG ]     &quot;required_con&quot;: &quot;0&quot;, 
[ceph-sh-node1][DEBUG ]     &quot;required_mon&quot;: []
[ceph-sh-node1][DEBUG ]   }, 
[ceph-sh-node1][DEBUG ]   &quot;monmap&quot;: {
[ceph-sh-node1][DEBUG ]     &quot;created&quot;: &quot;2019-02-13 22:05:49.949727&quot;, 
[ceph-sh-node1][DEBUG ]     &quot;epoch&quot;: 0, 
[ceph-sh-node1][DEBUG ]     &quot;features&quot;: {
[ceph-sh-node1][DEBUG ]       &quot;optional&quot;: [], 
[ceph-sh-node1][DEBUG ]       &quot;persistent&quot;: []
[ceph-sh-node1][DEBUG ]     }, 
[ceph-sh-node1][DEBUG ]     &quot;fsid&quot;: &quot;6e6d08a5-c4e9-43ae-90fa-166677400761&quot;, 
[ceph-sh-node1][DEBUG ]     &quot;modified&quot;: &quot;2019-02-13 22:05:49.949727&quot;, 
[ceph-sh-node1][DEBUG ]     &quot;mons&quot;: [
[ceph-sh-node1][DEBUG ]       {
[ceph-sh-node1][DEBUG ]         &quot;addr&quot;: &quot;192.168.59.201:6789/0&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node1&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.59.201:6789/0&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;rank&quot;: 0
[ceph-sh-node1][DEBUG ]       }, 
[ceph-sh-node1][DEBUG ]       {
[ceph-sh-node1][DEBUG ]         &quot;addr&quot;: &quot;0.0.0.0:0/1&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node2&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;public_addr&quot;: &quot;0.0.0.0:0/1&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;rank&quot;: 1
[ceph-sh-node1][DEBUG ]       }, 
[ceph-sh-node1][DEBUG ]       {
[ceph-sh-node1][DEBUG ]         &quot;addr&quot;: &quot;0.0.0.0:0/2&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node3&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;public_addr&quot;: &quot;0.0.0.0:0/2&quot;, 
[ceph-sh-node1][DEBUG ]         &quot;rank&quot;: 2
[ceph-sh-node1][DEBUG ]       }
[ceph-sh-node1][DEBUG ]     ]
[ceph-sh-node1][DEBUG ]   }, 
[ceph-sh-node1][DEBUG ]   &quot;name&quot;: &quot;ceph-sh-node1&quot;, 
[ceph-sh-node1][DEBUG ]   &quot;outside_quorum&quot;: [
[ceph-sh-node1][DEBUG ]     &quot;ceph-sh-node1&quot;
[ceph-sh-node1][DEBUG ]   ], 
[ceph-sh-node1][DEBUG ]   &quot;quorum&quot;: [], 
[ceph-sh-node1][DEBUG ]   &quot;rank&quot;: 0, 
[ceph-sh-node1][DEBUG ]   &quot;state&quot;: &quot;probing&quot;, 
[ceph-sh-node1][DEBUG ]   &quot;sync_provider&quot;: []
[ceph-sh-node1][DEBUG ] }
[ceph-sh-node1][DEBUG ] ********************************************************************************
[ceph-sh-node1][INFO  ] monitor: mon.ceph-sh-node1 is running
[ceph-sh-node1][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node1.asok mon_status
[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-sh-node2 ...
[ceph-sh-node2][DEBUG ] connection detected need for sudo
[ceph-sh-node2][DEBUG ] connected to host: ceph-sh-node2 
[ceph-sh-node2][DEBUG ] detect platform information from remote host
[ceph-sh-node2][DEBUG ] detect machine type
[ceph-sh-node2][DEBUG ] find the location of an executable
[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.5.1804 Core
[ceph-sh-node2][DEBUG ] determining if provided host has same hostname in remote
[ceph-sh-node2][DEBUG ] get remote short hostname
[ceph-sh-node2][DEBUG ] deploying mon to ceph-sh-node2
[ceph-sh-node2][DEBUG ] get remote short hostname
[ceph-sh-node2][DEBUG ] remote hostname: ceph-sh-node2
[ceph-sh-node2][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[ceph-sh-node2][DEBUG ] create the mon path if it does not exist
[ceph-sh-node2][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-sh-node2/done
[ceph-sh-node2][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph-sh-node2/done
[ceph-sh-node2][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph-sh-node2.mon.keyring
[ceph-sh-node2][DEBUG ] create the monitor keyring file
[ceph-sh-node2][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i ceph-sh-node2 --keyring /var/lib/ceph/tmp/ceph-ceph-sh-node2.mon.keyring --setuser 167 --setgroup 167
[ceph-sh-node2][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph-sh-node2.mon.keyring
[ceph-sh-node2][DEBUG ] create a done file to avoid re-doing the mon deployment
[ceph-sh-node2][DEBUG ] create the init path if it does not exist
[ceph-sh-node2][INFO  ] Running command: sudo systemctl enable ceph.target
[ceph-sh-node2][INFO  ] Running command: sudo systemctl enable ceph-mon@ceph-sh-node2
[ceph-sh-node2][WARNIN] Created symlink from /etc/systemd/system/ceph-mon.target.wants/ceph-mon@ceph-sh-node2.service to /usr/lib/systemd/system/ceph-mon@.service.
[ceph-sh-node2][INFO  ] Running command: sudo systemctl start ceph-mon@ceph-sh-node2
[ceph-sh-node2][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node2.asok mon_status
[ceph-sh-node2][DEBUG ] ********************************************************************************
[ceph-sh-node2][DEBUG ] status for monitor: mon.ceph-sh-node2
[ceph-sh-node2][DEBUG ] {
[ceph-sh-node2][DEBUG ]   &quot;election_epoch&quot;: 1, 
[ceph-sh-node2][DEBUG ]   &quot;extra_probe_peers&quot;: [
[ceph-sh-node2][DEBUG ]     &quot;192.168.59.201:6789/0&quot;, 
[ceph-sh-node2][DEBUG ]     &quot;192.168.59.203:6789/0&quot;
[ceph-sh-node2][DEBUG ]   ], 
[ceph-sh-node2][DEBUG ]   &quot;feature_map&quot;: {
[ceph-sh-node2][DEBUG ]     &quot;mon&quot;: [
[ceph-sh-node2][DEBUG ]       {
[ceph-sh-node2][DEBUG ]         &quot;features&quot;: &quot;0x3ffddff8ffa4fffb&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;num&quot;: 1, 
[ceph-sh-node2][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;
[ceph-sh-node2][DEBUG ]       }
[ceph-sh-node2][DEBUG ]     ]
[ceph-sh-node2][DEBUG ]   }, 
[ceph-sh-node2][DEBUG ]   &quot;features&quot;: {
[ceph-sh-node2][DEBUG ]     &quot;quorum_con&quot;: &quot;0&quot;, 
[ceph-sh-node2][DEBUG ]     &quot;quorum_mon&quot;: [], 
[ceph-sh-node2][DEBUG ]     &quot;required_con&quot;: &quot;0&quot;, 
[ceph-sh-node2][DEBUG ]     &quot;required_mon&quot;: []
[ceph-sh-node2][DEBUG ]   }, 
[ceph-sh-node2][DEBUG ]   &quot;monmap&quot;: {
[ceph-sh-node2][DEBUG ]     &quot;created&quot;: &quot;2019-02-13 22:05:54.402957&quot;, 
[ceph-sh-node2][DEBUG ]     &quot;epoch&quot;: 0, 
[ceph-sh-node2][DEBUG ]     &quot;features&quot;: {
[ceph-sh-node2][DEBUG ]       &quot;optional&quot;: [], 
[ceph-sh-node2][DEBUG ]       &quot;persistent&quot;: []
[ceph-sh-node2][DEBUG ]     }, 
[ceph-sh-node2][DEBUG ]     &quot;fsid&quot;: &quot;6e6d08a5-c4e9-43ae-90fa-166677400761&quot;, 
[ceph-sh-node2][DEBUG ]     &quot;modified&quot;: &quot;2019-02-13 22:05:54.402957&quot;, 
[ceph-sh-node2][DEBUG ]     &quot;mons&quot;: [
[ceph-sh-node2][DEBUG ]       {
[ceph-sh-node2][DEBUG ]         &quot;addr&quot;: &quot;192.168.59.201:6789/0&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node1&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.59.201:6789/0&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;rank&quot;: 0
[ceph-sh-node2][DEBUG ]       }, 
[ceph-sh-node2][DEBUG ]       {
[ceph-sh-node2][DEBUG ]         &quot;addr&quot;: &quot;192.168.59.202:6789/0&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node2&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.59.202:6789/0&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;rank&quot;: 1
[ceph-sh-node2][DEBUG ]       }, 
[ceph-sh-node2][DEBUG ]       {
[ceph-sh-node2][DEBUG ]         &quot;addr&quot;: &quot;0.0.0.0:0/2&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node3&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;public_addr&quot;: &quot;0.0.0.0:0/2&quot;, 
[ceph-sh-node2][DEBUG ]         &quot;rank&quot;: 2
[ceph-sh-node2][DEBUG ]       }
[ceph-sh-node2][DEBUG ]     ]
[ceph-sh-node2][DEBUG ]   }, 
[ceph-sh-node2][DEBUG ]   &quot;name&quot;: &quot;ceph-sh-node2&quot;, 
[ceph-sh-node2][DEBUG ]   &quot;outside_quorum&quot;: [], 
[ceph-sh-node2][DEBUG ]   &quot;quorum&quot;: [], 
[ceph-sh-node2][DEBUG ]   &quot;rank&quot;: 1, 
[ceph-sh-node2][DEBUG ]   &quot;state&quot;: &quot;electing&quot;, 
[ceph-sh-node2][DEBUG ]   &quot;sync_provider&quot;: []
[ceph-sh-node2][DEBUG ] }
[ceph-sh-node2][DEBUG ] ********************************************************************************
[ceph-sh-node2][INFO  ] monitor: mon.ceph-sh-node2 is running
[ceph-sh-node2][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node2.asok mon_status
[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-sh-node3 ...
[ceph-sh-node3][DEBUG ] connection detected need for sudo
[ceph-sh-node3][DEBUG ] connected to host: ceph-sh-node3 
[ceph-sh-node3][DEBUG ] detect platform information from remote host
[ceph-sh-node3][DEBUG ] detect machine type
[ceph-sh-node3][DEBUG ] find the location of an executable
[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.5.1804 Core
[ceph-sh-node3][DEBUG ] determining if provided host has same hostname in remote
[ceph-sh-node3][DEBUG ] get remote short hostname
[ceph-sh-node3][DEBUG ] deploying mon to ceph-sh-node3
[ceph-sh-node3][DEBUG ] get remote short hostname
[ceph-sh-node3][DEBUG ] remote hostname: ceph-sh-node3
[ceph-sh-node3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[ceph-sh-node3][DEBUG ] create the mon path if it does not exist
[ceph-sh-node3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-sh-node3/done
[ceph-sh-node3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph-sh-node3/done
[ceph-sh-node3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph-sh-node3.mon.keyring
[ceph-sh-node3][DEBUG ] create the monitor keyring file
[ceph-sh-node3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i ceph-sh-node3 --keyring /var/lib/ceph/tmp/ceph-ceph-sh-node3.mon.keyring --setuser 167 --setgroup 167
[ceph-sh-node3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph-sh-node3.mon.keyring
[ceph-sh-node3][DEBUG ] create a done file to avoid re-doing the mon deployment
[ceph-sh-node3][DEBUG ] create the init path if it does not exist
[ceph-sh-node3][INFO  ] Running command: sudo systemctl enable ceph.target
[ceph-sh-node3][INFO  ] Running command: sudo systemctl enable ceph-mon@ceph-sh-node3
[ceph-sh-node3][WARNIN] Created symlink from /etc/systemd/system/ceph-mon.target.wants/ceph-mon@ceph-sh-node3.service to /usr/lib/systemd/system/ceph-mon@.service.
[ceph-sh-node3][INFO  ] Running command: sudo systemctl start ceph-mon@ceph-sh-node3
[ceph-sh-node3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node3.asok mon_status
[ceph-sh-node3][DEBUG ] ********************************************************************************
[ceph-sh-node3][DEBUG ] status for monitor: mon.ceph-sh-node3
[ceph-sh-node3][DEBUG ] {
[ceph-sh-node3][DEBUG ]   &quot;election_epoch&quot;: 1, 
[ceph-sh-node3][DEBUG ]   &quot;extra_probe_peers&quot;: [
[ceph-sh-node3][DEBUG ]     &quot;192.168.59.201:6789/0&quot;, 
[ceph-sh-node3][DEBUG ]     &quot;192.168.59.202:6789/0&quot;
[ceph-sh-node3][DEBUG ]   ], 
[ceph-sh-node3][DEBUG ]   &quot;feature_map&quot;: {
[ceph-sh-node3][DEBUG ]     &quot;mon&quot;: [
[ceph-sh-node3][DEBUG ]       {
[ceph-sh-node3][DEBUG ]         &quot;features&quot;: &quot;0x3ffddff8ffa4fffb&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;num&quot;: 1, 
[ceph-sh-node3][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;
[ceph-sh-node3][DEBUG ]       }
[ceph-sh-node3][DEBUG ]     ]
[ceph-sh-node3][DEBUG ]   }, 
[ceph-sh-node3][DEBUG ]   &quot;features&quot;: {
[ceph-sh-node3][DEBUG ]     &quot;quorum_con&quot;: &quot;0&quot;, 
[ceph-sh-node3][DEBUG ]     &quot;quorum_mon&quot;: [], 
[ceph-sh-node3][DEBUG ]     &quot;required_con&quot;: &quot;0&quot;, 
[ceph-sh-node3][DEBUG ]     &quot;required_mon&quot;: []
[ceph-sh-node3][DEBUG ]   }, 
[ceph-sh-node3][DEBUG ]   &quot;monmap&quot;: {
[ceph-sh-node3][DEBUG ]     &quot;created&quot;: &quot;2019-02-13 22:05:58.789759&quot;, 
[ceph-sh-node3][DEBUG ]     &quot;epoch&quot;: 0, 
[ceph-sh-node3][DEBUG ]     &quot;features&quot;: {
[ceph-sh-node3][DEBUG ]       &quot;optional&quot;: [], 
[ceph-sh-node3][DEBUG ]       &quot;persistent&quot;: []
[ceph-sh-node3][DEBUG ]     }, 
[ceph-sh-node3][DEBUG ]     &quot;fsid&quot;: &quot;6e6d08a5-c4e9-43ae-90fa-166677400761&quot;, 
[ceph-sh-node3][DEBUG ]     &quot;modified&quot;: &quot;2019-02-13 22:05:58.789759&quot;, 
[ceph-sh-node3][DEBUG ]     &quot;mons&quot;: [
[ceph-sh-node3][DEBUG ]       {
[ceph-sh-node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.59.202:6789/0&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node2&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.59.202:6789/0&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;rank&quot;: 0
[ceph-sh-node3][DEBUG ]       }, 
[ceph-sh-node3][DEBUG ]       {
[ceph-sh-node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.59.203:6789/0&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node3&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.59.203:6789/0&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;rank&quot;: 1
[ceph-sh-node3][DEBUG ]       }, 
[ceph-sh-node3][DEBUG ]       {
[ceph-sh-node3][DEBUG ]         &quot;addr&quot;: &quot;0.0.0.0:0/1&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;name&quot;: &quot;ceph-sh-node1&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;public_addr&quot;: &quot;0.0.0.0:0/1&quot;, 
[ceph-sh-node3][DEBUG ]         &quot;rank&quot;: 2
[ceph-sh-node3][DEBUG ]       }
[ceph-sh-node3][DEBUG ]     ]
[ceph-sh-node3][DEBUG ]   }, 
[ceph-sh-node3][DEBUG ]   &quot;name&quot;: &quot;ceph-sh-node3&quot;, 
[ceph-sh-node3][DEBUG ]   &quot;outside_quorum&quot;: [], 
[ceph-sh-node3][DEBUG ]   &quot;quorum&quot;: [], 
[ceph-sh-node3][DEBUG ]   &quot;rank&quot;: 1, 
[ceph-sh-node3][DEBUG ]   &quot;state&quot;: &quot;electing&quot;, 
[ceph-sh-node3][DEBUG ]   &quot;sync_provider&quot;: []
[ceph-sh-node3][DEBUG ] }
[ceph-sh-node3][DEBUG ] ********************************************************************************
[ceph-sh-node3][INFO  ] monitor: mon.ceph-sh-node3 is running
[ceph-sh-node3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node3.asok mon_status
[ceph_deploy.mon][INFO  ] processing monitor mon.ceph-sh-node1
[ceph-sh-node1][DEBUG ] connection detected need for sudo
[ceph-sh-node1][DEBUG ] connected to host: ceph-sh-node1 
[ceph-sh-node1][DEBUG ] detect platform information from remote host
[ceph-sh-node1][DEBUG ] detect machine type
[ceph-sh-node1][DEBUG ] find the location of an executable
[ceph-sh-node1][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node1.asok mon_status
[ceph_deploy.mon][WARNIN] mon.ceph-sh-node1 monitor is not yet in quorum, tries left: 5
[ceph_deploy.mon][WARNIN] waiting 5 seconds before retrying
[ceph-sh-node1][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node1.asok mon_status
[ceph_deploy.mon][INFO  ] mon.ceph-sh-node1 monitor has reached quorum!
[ceph_deploy.mon][INFO  ] processing monitor mon.ceph-sh-node2
[ceph-sh-node2][DEBUG ] connection detected need for sudo
[ceph-sh-node2][DEBUG ] connected to host: ceph-sh-node2 
[ceph-sh-node2][DEBUG ] detect platform information from remote host
[ceph-sh-node2][DEBUG ] detect machine type
[ceph-sh-node2][DEBUG ] find the location of an executable
[ceph-sh-node2][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node2.asok mon_status
[ceph_deploy.mon][INFO  ] mon.ceph-sh-node2 monitor has reached quorum!
[ceph_deploy.mon][INFO  ] processing monitor mon.ceph-sh-node3
[ceph-sh-node3][DEBUG ] connection detected need for sudo
[ceph-sh-node3][DEBUG ] connected to host: ceph-sh-node3 
[ceph-sh-node3][DEBUG ] detect platform information from remote host
[ceph-sh-node3][DEBUG ] detect machine type
[ceph-sh-node3][DEBUG ] find the location of an executable
[ceph-sh-node3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-sh-node3.asok mon_status
[ceph_deploy.mon][INFO  ] mon.ceph-sh-node3 monitor has reached quorum!
[ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[ceph_deploy.mon][INFO  ] Running gatherkeys...
[ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmptSPgFH
[ceph-sh-node1][DEBUG ] connection detected need for sudo
[ceph-sh-node1][DEBUG ] connected to host: ceph-sh-node1 
[ceph-sh-node1][DEBUG ] detect platform information from remote host
[ceph-sh-node1][DEBUG ] detect machine type
[ceph-sh-node1][DEBUG ] get remote short hostname
[ceph-sh-node1][DEBUG ] fetch remote file
[ceph-sh-node1][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.ceph-sh-node1.asok mon_status
[ceph-sh-node1][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-sh-node1/keyring auth get client.admin
[ceph-sh-node1][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-sh-node1/keyring auth get client.bootstrap-mds
[ceph-sh-node1][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-sh-node1/keyring auth get client.bootstrap-mgr
[ceph-sh-node1][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-sh-node1/keyring auth get client.bootstrap-osd
[ceph-sh-node1][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-sh-node1/keyring auth get client.bootstrap-rgw
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring
[ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmptSPgFH
[ceph-sh-admin@ceph-sh-admin ceph-deploy]$ ll
total 476
-rw------- 1 ceph-sh-admin ceph-sh-admin    113 Feb 13 22:06 ceph.bootstrap-mds.keyring
-rw------- 1 ceph-sh-admin ceph-sh-admin    113 Feb 13 22:06 ceph.bootstrap-mgr.keyring
-rw------- 1 ceph-sh-admin ceph-sh-admin    113 Feb 13 22:06 ceph.bootstrap-osd.keyring
-rw------- 1 ceph-sh-admin ceph-sh-admin    113 Feb 13 22:06 ceph.bootstrap-rgw.keyring
-rw------- 1 ceph-sh-admin ceph-sh-admin    151 Feb 13 22:06 ceph.client.admin.keyring
-rw-rw-r-- 1 ceph-sh-admin ceph-sh-admin    474 Feb 13 22:00 ceph.conf
-rw-rw-r-- 1 ceph-sh-admin ceph-sh-admin 270494 Feb 13 22:06 ceph-deploy-ceph.log
-rw------- 1 ceph-sh-admin ceph-sh-admin     73 Feb 13 21:51 ceph.mon.keyring
</code></pre></li>

<li><p>mgr</p>

<pre><code>[ceph-sh-admin@ceph-sh-admin ceph-deploy]$ ceph-deploy mgr create ceph-sh-node1
[ceph_deploy.conf][DEBUG ] found configuration file at: /home/ceph-sh-admin/.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy mgr create ceph-sh-node1
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  mgr                           : [('ceph-sh-node1', 'ceph-sh-node1')]
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : create
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fae2f5c6ea8&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  func                          : &lt;function mgr at 0x7fae2fa1b0c8&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-sh-node1:ceph-sh-node1
[ceph-sh-node1][DEBUG ] connection detected need for sudo
[ceph-sh-node1][DEBUG ] connected to host: ceph-sh-node1 
[ceph-sh-node1][DEBUG ] detect platform information from remote host
[ceph-sh-node1][DEBUG ] detect machine type
[ceph_deploy.mgr][INFO  ] Distro info: CentOS Linux 7.5.1804 Core
[ceph_deploy.mgr][DEBUG ] remote host will use systemd
[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-sh-node1
[ceph-sh-node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[ceph-sh-node1][WARNIN] mgr keyring does not exist yet, creating one
[ceph-sh-node1][DEBUG ] create a keyring file
[ceph-sh-node1][DEBUG ] create path recursively if it doesn't exist
[ceph-sh-node1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.ceph-sh-node1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-ceph-sh-node1/keyring
[ceph-sh-node1][INFO  ] Running command: sudo systemctl enable ceph-mgr@ceph-sh-node1
[ceph-sh-node1][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@ceph-sh-node1.service to /usr/lib/systemd/system/ceph-mgr@.service.
[ceph-sh-node1][INFO  ] Running command: sudo systemctl start ceph-mgr@ceph-sh-node1
[ceph-sh-node1][INFO  ] Running command: sudo systemctl enable ceph.target
</code></pre></li>

<li><p>osd</p>

<pre><code>[ceph-sh-admin@ceph-sh-admin ceph-deploy]$ ceph-deploy osd create --data /dev/sdb ceph-sh-node1
[ceph_deploy.conf][DEBUG ] found configuration file at: /home/ceph-sh-admin/.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy osd create --data /dev/sdb ceph-sh-node1
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  bluestore                     : None
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fca63f71d88&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[ceph_deploy.cli][INFO  ]  block_wal                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  journal                       : None
[ceph_deploy.cli][INFO  ]  subcommand                    : create
[ceph_deploy.cli][INFO  ]  host                          : ceph-sh-node1
[ceph_deploy.cli][INFO  ]  filestore                     : None
[ceph_deploy.cli][INFO  ]  func                          : &lt;function osd at 0x7fca643c6848&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  zap_disk                      : False
[ceph_deploy.cli][INFO  ]  data                          : /dev/sdb
[ceph_deploy.cli][INFO  ]  block_db                      : None
[ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  debug                         : False
[ceph_deploy.osd][DEBUG ] Creating OSD on cluster ceph with data device /dev/sdb
[ceph-sh-node1][DEBUG ] connection detected need for sudo
[ceph-sh-node1][DEBUG ] connected to host: ceph-sh-node1 
[ceph-sh-node1][DEBUG ] detect platform information from remote host
[ceph-sh-node1][DEBUG ] detect machine type
[ceph-sh-node1][DEBUG ] find the location of an executable
[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.5.1804 Core
[ceph_deploy.osd][DEBUG ] Deploying osd to ceph-sh-node1
[ceph-sh-node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[ceph-sh-node1][WARNIN] osd keyring does not exist yet, creating one
[ceph-sh-node1][DEBUG ] create a keyring file
[ceph-sh-node1][DEBUG ] find the location of an executable
[ceph-sh-node1][INFO  ] Running command: sudo /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/sdb
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph-authtool --gen-print-key
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring -i - osd new 0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb
[ceph-sh-node1][DEBUG ] Running command: /usr/sbin/vgcreate --force --yes ceph-edf80fef-6546-4e23-8949-4d1417459a73 /dev/sdb
[ceph-sh-node1][DEBUG ]  stdout: Physical volume &quot;/dev/sdb&quot; successfully created.
[ceph-sh-node1][DEBUG ]  stdout: Volume group &quot;ceph-edf80fef-6546-4e23-8949-4d1417459a73&quot; successfully created
[ceph-sh-node1][DEBUG ] Running command: /usr/sbin/lvcreate --yes -l 100%FREE -n osd-block-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb ceph-edf80fef-6546-4e23-8949-4d1417459a73
[ceph-sh-node1][DEBUG ]  stdout: Logical volume &quot;osd-block-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb&quot; created.
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph-authtool --gen-print-key
[ceph-sh-node1][DEBUG ] Running command: /bin/mount -t tmpfs tmpfs /var/lib/ceph/osd/ceph-0
[ceph-sh-node1][DEBUG ] Running command: /usr/sbin/restorecon /var/lib/ceph/osd/ceph-0
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -h ceph:ceph /dev/ceph-edf80fef-6546-4e23-8949-4d1417459a73/osd-block-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -R ceph:ceph /dev/dm-2
[ceph-sh-node1][DEBUG ] Running command: /bin/ln -s /dev/ceph-edf80fef-6546-4e23-8949-4d1417459a73/osd-block-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb /var/lib/ceph/osd/ceph-0/block
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /var/lib/ceph/osd/ceph-0/activate.monmap
[ceph-sh-node1][DEBUG ]  stderr: got monmap epoch 1
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph-authtool /var/lib/ceph/osd/ceph-0/keyring --create-keyring --name osd.0 --add-key AQA3MWRcx0MpJBAATF1r6j6nZTYl/zsXDlUuTg==
[ceph-sh-node1][DEBUG ]  stdout: creating /var/lib/ceph/osd/ceph-0/keyring
[ceph-sh-node1][DEBUG ] added entity osd.0 auth auth(auid = 18446744073709551615 key=AQA3MWRcx0MpJBAATF1r6j6nZTYl/zsXDlUuTg== with 0 caps)
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0/keyring
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0/
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph-osd --cluster ceph --osd-objectstore bluestore --mkfs -i 0 --monmap /var/lib/ceph/osd/ceph-0/activate.monmap --keyfile - --osd-data /var/lib/ceph/osd/ceph-0/ --osd-uuid 0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb --setuser ceph --setgroup ceph
[ceph-sh-node1][DEBUG ] --&gt; ceph-volume lvm prepare successful for: /dev/sdb
[ceph-sh-node1][DEBUG ] Running command: /bin/ceph-bluestore-tool --cluster=ceph prime-osd-dir --dev /dev/ceph-edf80fef-6546-4e23-8949-4d1417459a73/osd-block-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb --path /var/lib/ceph/osd/ceph-0 --no-mon-config
[ceph-sh-node1][DEBUG ] Running command: /bin/ln -snf /dev/ceph-edf80fef-6546-4e23-8949-4d1417459a73/osd-block-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb /var/lib/ceph/osd/ceph-0/block
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -h ceph:ceph /var/lib/ceph/osd/ceph-0/block
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -R ceph:ceph /dev/dm-2
[ceph-sh-node1][DEBUG ] Running command: /bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0
[ceph-sh-node1][DEBUG ] Running command: /bin/systemctl enable ceph-volume@lvm-0-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb
[ceph-sh-node1][DEBUG ]  stderr: Created symlink from /etc/systemd/system/multi-user.target.wants/ceph-volume@lvm-0-0bfacce8-06f0-4fcd-8aa7-8c81c117d8fb.service to /usr/lib/systemd/system/ceph-volume@.service.
[ceph-sh-node1][DEBUG ] Running command: /bin/systemctl enable --runtime ceph-osd@0
[ceph-sh-node1][DEBUG ]  stderr: Created symlink from /run/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /usr/lib/systemd/system/ceph-osd@.service.
[ceph-sh-node1][DEBUG ] Running command: /bin/systemctl start ceph-osd@0
[ceph-sh-node1][DEBUG ] --&gt; ceph-volume lvm activate successful for osd ID: 0
[ceph-sh-node1][DEBUG ] --&gt; ceph-volume lvm create successful for: /dev/sdb
[ceph-sh-node1][INFO  ] checking OSD status...
[ceph-sh-node1][DEBUG ] find the location of an executable
[ceph-sh-node1][INFO  ] Running command: sudo /bin/ceph --cluster=ceph osd stat --format=json
[ceph_deploy.osd][DEBUG ] Host ceph-sh-node1 is now ready for osd use.
</code></pre></li>
</ol>


    
    
        <div class="chevrons">
    <div id="navigation">
<a class="nav nav-prev" href="/cloud/cloud-storage/ceph/operations/ceph-osd/" title="ceph-osd"> <i class="fa fa-chevron-left"></i><label>ceph-osd</label></a>
    <a class="nav nav-next" href="/cloud/cloud-storage/ceph/operations/ceph-mgr-dashboard/" title="ceph-mgr-dashboard" style="margin-right: 0px;"><label>ceph-mgr-dashboard</label><i class="fa fa-chevron-right"></i></a></div>
  </div>

  </section>
</article>

<footer>

<div class="footline">
    

    

  

    <div class="github-link">
      <a href="https://github.com/vjeantet/hugo-theme-docdock/edit/master/exampleSite/content/cloud-storage/ceph/operations/ceph-deploy.md" target="blank"><i class="fa fa-code-fork"></i>
        Improve this page</a>
    </div>
  </div>


	<div>


  
    Create a content/_footer.md file to customize the footer content
  



	</div>
</footer>

<script src="/cloud/js/clipboard.min.js"></script>

<link href="/cloud/css/featherlight.min.css" rel="stylesheet">
<script src="/cloud/js/featherlight.min.js"></script>



<script src="/cloud/theme-flex/script.js"></script>

    

    
    

    
  </body>
</html>